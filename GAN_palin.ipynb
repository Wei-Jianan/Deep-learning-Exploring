{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.035294Z",
     "start_time": "2018-06-18T17:18:36.067544Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "import numpy as np\n",
    "\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.046915Z",
     "start_time": "2018-06-18T17:18:37.037015Z"
    }
   },
   "outputs": [],
   "source": [
    "X = nd.random_normal(shape=(1000, 2))\n",
    "A = nd.array([[1, 2], [-0.1, 0.5]])\n",
    "b = nd.array([1, 2])\n",
    "X = nd.dot(X,A) + b\n",
    "Y = nd.ones(shape=(1000,1))\n",
    "\n",
    "# and stick them into an iterator\n",
    "batch_size = 4\n",
    "train_data = mx.io.NDArrayIter(X, Y, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.052359Z",
     "start_time": "2018-06-18T17:18:37.048852Z"
    }
   },
   "outputs": [],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.169743Z",
     "start_time": "2018-06-18T17:18:37.054329Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0].asnumpy(),X[:,1].asnumpy())\n",
    "plt.show()\n",
    "print(\"The covariance matrix is\")\n",
    "print(nd.dot(A, A.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.175510Z",
     "start_time": "2018-06-18T17:18:37.172110Z"
    }
   },
   "outputs": [],
   "source": [
    "netG = nn.Sequential()\n",
    "with netG.name_scope():\n",
    "    netG.add(nn.Dense(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.180350Z",
     "start_time": "2018-06-18T17:18:37.177772Z"
    }
   },
   "outputs": [],
   "source": [
    "# netG.collect_params()['sequential6_dense0_weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.323658Z",
     "start_time": "2018-06-18T17:18:37.320300Z"
    }
   },
   "outputs": [],
   "source": [
    "netD = nn.Sequential()\n",
    "with netD.name_scope():\n",
    "    netD.add(nn.Dense(5, activation='tanh'))\n",
    "    netD.add(nn.Dense(3, activation='tanh'))\n",
    "    netD.add(nn.Dense(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.525109Z",
     "start_time": "2018-06-18T17:18:37.519516Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "netG.initialize(init=mx.init.Normal(0.02))\n",
    "netD.initialize(init=mx.init.Normal(0.02))\n",
    "\n",
    "trainerG = gluon.Trainer(netG.collect_params(), 'adam', {'learning_rate': 0.01})\n",
    "trainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': 0.05})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:18:37.735176Z",
     "start_time": "2018-06-18T17:18:37.731486Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "real_label = mx.nd.zeros((batch_size,), ctx=ctx)\n",
    "fake_label = mx.nd.ones((batch_size,), ctx=ctx)\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "# set up logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-18T17:19:37.089091Z",
     "start_time": "2018-06-18T17:18:37.939155Z"
    }
   },
   "outputs": [],
   "source": [
    "stamp =  datetime.now().strftime('%Y_%m_%d-%H_%M')\n",
    "for epoch in range(50):\n",
    "    tic = time.time()\n",
    "    train_data.reset()\n",
    "    for i, batch in enumerate(train_data):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real_t\n",
    "        data = batch.data[0].as_in_context(ctx)\n",
    "        noise = nd.random_normal(shape=(batch_size, 2), ctx=ctx)\n",
    "\n",
    "        with autograd.record():\n",
    "            real_output = netD(data)\n",
    "            errD_real = loss(real_output, real_label)\n",
    "\n",
    "            fake = netG(noise)\n",
    "            fake_output = netD(fake.detach())\n",
    "            errD_fake = loss(fake_output, fake_label)\n",
    "            errD =  errD_real + errD_fake\n",
    "#             errD = -1 * errD\n",
    "            errD.backward()\n",
    "\n",
    "        trainerD.step(batch_size)\n",
    "        metric.update([real_label,], [real_output,])\n",
    "        metric.update([fake_label,], [fake_output,])\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        with autograd.record():\n",
    "            output = netD(fake)\n",
    "            errG = 1 * loss(output, real_label)\n",
    "#             errG = errG * -1\n",
    "            errG.backward()\n",
    "\n",
    "        trainerG.step(batch_size)\n",
    "\n",
    "    name, acc = metric.get()\n",
    "    metric.reset()\n",
    "    print('\\nbinary training acc at epoch %d: %s=%f' % (epoch, name, acc))\n",
    "    print('time: %f' % (time.time() - tic))\n",
    "    noise = nd.random_normal(shape=(100, 2), ctx=ctx)\n",
    "    fake = netG(noise)\n",
    "    plt.scatter(X[:, 0].asnumpy(),X[:,1].asnumpy())\n",
    "    plt.scatter(fake[:,0].asnumpy(),fake[:,1].asnumpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
