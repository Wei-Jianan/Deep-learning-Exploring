{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T19:26:24.928882Z",
     "start_time": "2018-08-27T19:26:24.925345Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import mxnet as mx\n",
    "import gluonbook as gb\n",
    "from mxnet import autograd, nd\n",
    "from mxnet import gluon\n",
    "import random\n",
    "import zipfile\n",
    "import time, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T14:59:54.344218Z",
     "start_time": "2018-08-27T14:59:54.336732Z"
    }
   },
   "outputs": [],
   "source": [
    "(corpus_indices, char_to_idx, idx_to_char,\n",
    " vocab_size) = gb.load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:48:30.541946Z",
     "start_time": "2018-08-27T17:48:30.536062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [[1. 0. 0. ... 0. 0. 0.]\n",
       "  [0. 0. 0. ... 0. 0. 0.]]\n",
       " <NDArray 2x1038 @cpu(0)>, \n",
       " [[0. 1. 0. ... 0. 0. 0.]\n",
       "  [0. 0. 0. ... 0. 0. 0.]]\n",
       " <NDArray 2x1038 @cpu(0)>, \n",
       " [[0. 0. 1. ... 0. 0. 0.]\n",
       "  [0. 0. 0. ... 0. 0. 0.]]\n",
       " <NDArray 2x1038 @cpu(0)>, \n",
       " [[0. 0. 0. ... 0. 0. 0.]\n",
       "  [0. 0. 0. ... 0. 0. 0.]]\n",
       " <NDArray 2x1038 @cpu(0)>, \n",
       " [[0. 0. 0. ... 0. 0. 0.]\n",
       "  [0. 0. 0. ... 0. 0. 0.]]\n",
       " <NDArray 2x1038 @cpu(0)>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_onehot(X, size):\n",
    "    return [nd.one_hot(x, size) for x in X.T]\n",
    "X = nd.arange(10).reshape(2, 5)\n",
    "inputs = to_onehot(X, vocab_size)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:00:04.803708Z",
     "start_time": "2018-08-27T17:00:04.798857Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs = vocab_size \n",
    "num_hidden = 256\n",
    "num_output = vocab_size\n",
    "ctx = gb.try_gpu()\n",
    "def get_params():\n",
    "    def get_initialized(shape):\n",
    "        return nd.random_normal(scale=0.01, shape=shape, ctx=ctx)\n",
    "    W_xh = get_initialized(shape=(num_inputs, num_hidden))\n",
    "    W_hh = get_initialized(shape=(num_hidden, num_hidden))\n",
    "    b_h = nd.zeros(shape=(num_hidden,))\n",
    "    \n",
    "    W_hy = get_initialized(shape=(num_hidden, num_output))\n",
    "    b_y = nd.zeros(shape=(num_output,))\n",
    "    \n",
    "    params = [W_xh, W_hh, b_h, W_hy, b_y]\n",
    "    for param in params:\n",
    "        param.attach_grad()\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:00:06.069330Z",
     "start_time": "2018-08-27T17:00:06.062634Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1038, 256)\n",
      "(256, 256)\n",
      "(256,)\n",
      "(256, 1038)\n",
      "(1038,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda param: print(param.shape),\n",
    "         get_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:00:06.742333Z",
     "start_time": "2018-08-27T17:00:06.738940Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_rnn_state(batch_size, num_hiddens, ctx=None):\n",
    "    return nd.zeros(shape=(batch_size, num_hiddens), ctx=ctx),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:00:07.299471Z",
     "start_time": "2018-08-27T17:00:07.294567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_rnn_state(batch_size=2,num_hiddens=10)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:10.130604Z",
     "start_time": "2018-08-27T21:00:10.126109Z"
    }
   },
   "outputs": [],
   "source": [
    "def rnn(inputs, state, params):\n",
    "    W_xh, W_hh, b_h, W_hy, b_y = params\n",
    "    H, = state\n",
    "    output = []\n",
    "    for X in inputs:\n",
    "#         print(\"X * W_xh shape:\", nd.dot(X, W_xh).shape)\n",
    "#         print('X * W_hh shape:', nd.dot(H, W_hh).shape)\n",
    "#         print('b_h shape:', b_h.shape)\n",
    "        H = nd.relu(nd.dot(X, W_xh) + nd.dot(H, W_hh) + b_h)\n",
    "#         H = nd.tanh(nd.dot(X, W_xh) + nd.dot(H, W_hh) + b_h)\n",
    "        Y = nd.dot(H, W_hy) + b_y\n",
    "        output.append(Y)\n",
    "    return output, (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T17:01:44.105305Z",
     "start_time": "2018-08-27T17:01:44.086233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of inputs: 5 input shape: (2, 1038)\n",
      "X * W_xh shape: (2, 256)\n",
      "X * W_hh shape: (2, 256)\n",
      "b_h shape: (256,)\n",
      "X * W_xh shape: (2, 256)\n",
      "X * W_hh shape: (2, 256)\n",
      "b_h shape: (256,)\n",
      "X * W_xh shape: (2, 256)\n",
      "X * W_hh shape: (2, 256)\n",
      "b_h shape: (256,)\n",
      "X * W_xh shape: (2, 256)\n",
      "X * W_hh shape: (2, 256)\n",
      "b_h shape: (256,)\n",
      "X * W_xh shape: (2, 256)\n",
      "X * W_hh shape: (2, 256)\n",
      "b_h shape: (256,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5, (2, 1038), (2, 256))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = init_rnn_state(X.shape[0], num_hidden, ctx)\n",
    "inputs = to_onehot(X.as_in_context(ctx), vocab_size)\n",
    "print('num of inputs:', len(inputs), 'input shape:', inputs[0].shape)\n",
    "params = get_params()\n",
    "outputs, state_new = rnn(inputs, state, params)\n",
    "len(outputs), outputs[0].shape, state_new[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:11.437423Z",
     "start_time": "2018-08-27T21:00:11.431818Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_rnn(prefix, num_chars, rnn, params, init_rnn_state,\n",
    "                num_hiddens, vocab_size, ctx, idx_to_char, char_to_idx):\n",
    "    state = init_rnn_state(1, num_hiddens=num_hidden, ctx=ctx)\n",
    "    output = [char_to_idx[prefix[0]]]\n",
    "    for t in range(len(prefix) + num_chars):\n",
    "        X = to_onehot(nd.array([output[-1]], ctx=ctx), vocab_size)\n",
    "#         print('haha')\n",
    "        \n",
    "        Y, state = rnn(X, state, params)\n",
    "        \n",
    "        if t < len(prefix) -1:\n",
    "            output.append(char_to_idx[prefix[t + 1]])\n",
    "        else:\n",
    "            output.append(int(Y[0].argmax(axis=1).asscalar()))\n",
    "        \n",
    "    return ''.join([idx_to_char[i] for i in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T20:42:36.820874Z",
     "start_time": "2018-08-27T20:42:36.802149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'分开堂舍uuuuuuuuu'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_rnn('分开', 10, rnn, params, init_rnn_state, num_hidden, vocab_size,\n",
    "            ctx, idx_to_char, char_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:00:15.020655Z",
     "start_time": "2018-08-27T21:00:15.011379Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                          vocab_size, ctx, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, is_random_iter, num_epochs, num_steps,\n",
    "                          lr, clipping_theta, batch_size, pred_period,\n",
    "                          pred_len, prefixes):\n",
    "    if is_random_iter:\n",
    "        data_iter_fn = gb.data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = gb.data_iter_consecutive\n",
    "    params = get_params()\n",
    "    loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if not is_random_iter:  # 如使用相邻采样，在 epoch 开始时初始化隐藏变量。\n",
    "            state = init_rnn_state(batch_size, num_hiddens, ctx)\n",
    "        loss_sum, start = 0.0, time.time()\n",
    "        data_iter = data_iter_fn(corpus_indices, batch_size, num_steps, ctx)\n",
    "        for t, (X, Y) in enumerate(data_iter):\n",
    "            if is_random_iter: # 如使用随机采样，在每个小批量更新前初始化隐藏变量。\n",
    "                state = init_rnn_state(batch_size, num_hiddens, ctx)\n",
    "            else:  # 否则需要使用 detach 函数从计算图分离隐藏状态变量。\n",
    "#                 pass\n",
    "                for s in state:\n",
    "                    s.detach()\n",
    "            with autograd.record():\n",
    "                inputs = to_onehot(X, vocab_size)\n",
    "                # outputs 有 num_steps 个形状为 (batch_size, vocab_size) 的矩阵。\n",
    "                (outputs, state) = rnn(inputs, state, params)\n",
    "                # 拼接之后形状为 (num_steps * batch_size, vocab_size)。\n",
    "                outputs = nd.concat(*outputs, dim=0)\n",
    "                # Y 的形状是 (batch_size, num_steps)，转置后再变成长\n",
    "                # batch * num_steps 的向量，这样跟输出的行一一对应。\n",
    "                y = Y.T.reshape((-1,))\n",
    "                # 使用交叉熵损失计算平均分类误差。\n",
    "                l = loss(outputs, y).mean()\n",
    "            l.backward()\n",
    "            # 裁剪梯度后使用 SGD 更新权重。\n",
    "            grad_clipping(params, clipping_theta, ctx)\n",
    "            gb.sgd(params, lr, 1)  # 因为已经误差取过均值，梯度不用再做平均。\n",
    "            loss_sum += l.asscalar()\n",
    "\n",
    "        if (epoch + 1) % pred_period == 0:\n",
    "            print('epoch %d, perplexity %f, time %.2f sec'  % (\n",
    "                epoch + 1, math.exp(loss_sum / (t + 1)),\n",
    "                     time.time() - start))\n",
    "            for prefix in prefixes:\n",
    "                print(' -', predict_rnn(\n",
    "                    prefix, pred_len, rnn, params, init_rnn_state,\n",
    "                    num_hiddens, vocab_size, ctx, idx_to_char, char_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T21:01:43.740995Z",
     "start_time": "2018-08-27T21:00:15.283557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, perplexity 54153.847003, time 0.92 sec\n",
      " - 分开                                                   \n",
      " - 不分开                                                   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-ccd0084ca0f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                       \u001b[0mchar_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                       \u001b[0mclipping_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                       prefixes)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-1e4fa32c1103>\u001b[0m in \u001b[0;36mtrain_and_predict_rnn\u001b[0;34m(rnn, get_params, init_rnn_state, num_hiddens, vocab_size, ctx, corpus_indices, idx_to_char, char_to_idx, is_random_iter, num_epochs, num_steps, lr, clipping_theta, batch_size, pred_period, pred_len, prefixes)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;31m# 裁剪梯度后使用 SGD 更新权重。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mgrad_clipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipping_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 因为已经误差取过均值，梯度不用再做平均。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mloss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-019185201f90>\u001b[0m in \u001b[0;36mgrad_clipping\u001b[0;34m(params, theta, ctx)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnorm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1896\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1876\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   1877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "num_steps = 35\n",
    "batch_size = 32\n",
    "lr = 1e2\n",
    "clipping_theta = 1e-2\n",
    "prefixes = ['分开', '不分开']\n",
    "pred_period = 50\n",
    "pred_len = 50\n",
    "\n",
    "train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hidden,\n",
    "                      vocab_size, ctx, corpus_indices, idx_to_char,\n",
    "                      char_to_idx, True, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, batch_size, pred_period, pred_len,\n",
    "                      prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T20:58:14.351497Z",
     "start_time": "2018-08-27T20:52:06.537201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, perplexity 72.851587, time 0.97 sec\n",
      " - 分开 我想能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不\n",
      " - 不分开 我想你你想 我不能再不 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不能再想 我不\n",
      "epoch 100, perplexity 12.260469, time 0.95 sec\n",
      " - 分开我 说散依旧每日 一直走依 快使用碗 恨自不同 你不没纵 我想著努我 你思寄红不投 景色入秋 我该好这\n",
      " - 不分开 连是我 别怪我 印你 是因为很 一壶都酒 在来用碗的溪边 情晶莹的话滴 我爱你 你爱我 不地安的传有\n",
      "epoch 150, perplexity 4.000830, time 0.94 sec\n",
      " - 分开我遇见 我的伤口被狂拆暴 誓言太沉重泪被纵容 脸上 你的黑色幽默 想通 却又再的玩笑 想通 却又再考倒\n",
      " - 不分开 我已到能 你颗心悬 说是再这 你在我妈别重 然 后壁我 别怪我 三你 是因为闷了很 就伤 这念再血倒\n",
      "epoch 200, perplexity 2.281921, time 0.92 sec\n",
      " - 分开我遇攻 我的伤口被你拆封 誓言太沉重泪被 但那伦人已经不 我不耍的远模有样 什么兵器最喜欢 双截棍 -\n",
      " - 不分开 我 想带你在单车 我 想和你看棒球 想这样没担忧 唱着歌 一直走 我想就这样牵着你的手不放开 爱能不\n",
      "epoch 250, perplexity 1.770085, time 0.92 sec\n",
      " - 分开 停格内容不忠 所有回忆对着我进攻...... 古有云层 我不多努力向你奔跑 爱才送到 你却已在别人怀\n",
      " - 不分开 那在黑回 你却经离 我听再受我 走没有你在我有多烦恼多难熬) 穿过云层 我试著努力向你奔跑 爱才送到\n",
      "epoch 300, perplexity 1.474915, time 1.06 sec\n",
      " - 分开 停格内容不忠 所有回忆对着我进攻...... 所有回忆对着我进攻...... 古巴比伦王颁布了汉摩拉\n",
      " - 不分开觉 在格内 广场箱都我一 有谁啊 是在是你不想活 说你怎我面绕的怒火 我想揍你已经很久 别想躲 说你眼\n",
      "epoch 350, perplexity 1.497948, time 0.94 sec\n",
      " - 分开 问格内容不忠 所有回头 你已经离开我 不知不觉 我跟了这节奏 我该好好生活 不知不觉 默离什 不时来\n",
      " - 不分开觉 我已到伊斯坦 若知依悄 默离什 干一一 我想就你样牵着你 也逗你笑 你对我有多重要 我后悔没让你知\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-142-0dd2cdb095e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mchar_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mclipping_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_period\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                       prefixes)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-137-1e4fa32c1103>\u001b[0m in \u001b[0;36mtrain_and_predict_rnn\u001b[0;34m(rnn, get_params, init_rnn_state, num_hiddens, vocab_size, ctx, corpus_indices, idx_to_char, char_to_idx, is_random_iter, num_epochs, num_steps, lr, clipping_theta, batch_size, pred_period, pred_len, prefixes)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# 使用交叉熵损失计算平均分类误差。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;31m# 裁剪梯度后使用 SGD 更新权重。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mgrad_clipping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipping_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.6/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, out_grad, retain_graph, train_mode)\u001b[0m\n\u001b[1;32m   2094\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2096\u001b[0;31m             ctypes.c_void_p(0)))\n\u001b[0m\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtostype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hidden,\n",
    "                      vocab_size, ctx, corpus_indices, idx_to_char,\n",
    "                      char_to_idx, False, num_epochs, num_steps, lr,\n",
    "                      clipping_theta, batch_size, pred_period, pred_len,\n",
    "                      prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T14:38:26.038735Z",
     "start_time": "2018-08-27T14:38:26.034332Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_iter_consecutive(corpus_indices, batch_size, num_steps, ctx=None):\n",
    "    corpus_indices = nd.array(corpus_indices, ctx=ctx)\n",
    "    data_len = len(corpus_indices)\n",
    "    batch_len = data_len // batch_size\n",
    "    indices = corpus_indices[0: batch_size*batch_len].reshape((\n",
    "        batch_size, batch_len))\n",
    "    epoch_size = (batch_len - 1) // num_steps\n",
    "    for i in range(epoch_size):\n",
    "        i = i * num_steps\n",
    "        X = indices[:, i: i + num_steps]\n",
    "        Y = indices[:, i + 1: i + num_steps + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T18:06:39.242104Z",
     "start_time": "2018-08-27T18:06:39.238575Z"
    }
   },
   "outputs": [],
   "source": [
    "def grad_clipping(params, theta, ctx):\n",
    "    norm = nd.array([0.0], ctx)\n",
    "    for param in params:\n",
    "        norm += (param.grad ** 2).sum()\n",
    "    norm = norm.sqrt().asscalar()\n",
    "    if norm > theta:\n",
    "        for param in params:\n",
    "            param.grad[:] *= theta / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T18:12:30.874078Z",
     "start_time": "2018-08-27T18:12:30.868366Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-93-e55ac7c20252>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-93-e55ac7c20252>\"\u001b[0;36m, line \u001b[0;32m13\u001b[0m\n\u001b[0;31m    for epoch in range(num_epochs):\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def train_and_predict_rnn(rnn, get_params, init_rnn_state, num_hiddens,\n",
    "                          vocab_size, ctx, corpus_indices, idx_to_char,\n",
    "                          char_to_idx, is_random_iter, num_epochs, num_steps,\n",
    "                          lr, clipping_theta, batch_size, pred_period,\n",
    "                          pred_len, prefixes):\n",
    "    if is_random_iter:\n",
    "        data_iter_fn = gb.data_iter_random\n",
    "    else:\n",
    "        data_iter_fn = gb.data_iter_consecutive\n",
    "    params = get_params()\n",
    "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T14:44:49.675830Z",
     "start_time": "2018-08-27T14:44:49.669220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9.]\n",
       " [10. 11. 12. 13. 14. 15. 16. 17. 18. 19.]\n",
       " [20. 21. 22. 23. 24. 25. 26. 27. 28. 29.]\n",
       " [30. 31. 32. 33. 34. 35. 36. 37. 38. 39.]\n",
       " [40. 41. 42. 43. 44. 45. 46. 47. 48. 49.]]\n",
       "<NDArray 5x10 @cpu(0)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_indices = nd.array(my_seq)\n",
    "indices = corpus_indices[0 : 50].reshape((5, 10))\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-27T20:02:51.842392Z",
     "start_time": "2018-08-27T20:02:51.838849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
